project,goal,milestone
Cotomata,"Produce and deliver meeting-ready artifacts: a one-page summary, a short slide deck (1–6 slides) with speaker notes, and a Slack-ready summary that include final_patch diffs, test outputs, screenshots, blockers, and 3 clear next actions",
Cotomata,"Produce and deliver meeting-ready artifacts: a one-page summary, a short slide deck (1–6 slides) with speaker notes, and a Slack-ready summary that include final_patch diffs, test outputs, screenshots, blockers, and 3 clear next actions","Capture and save evidence: export Final Patch diff, Merge Diff, Test Output logs, Agent Evaluation form, and 4 cropped UI screenshots into docs/meeting/screenshots/ and docs/meeting/test_debug/ (verify file names and timestamps)."
Cotomata,"Produce and deliver meeting-ready artifacts: a one-page summary, a short slide deck (1–6 slides) with speaker notes, and a Slack-ready summary that include final_patch diffs, test outputs, screenshots, blockers, and 3 clear next actions","Draft one-page summary: populate docs/meeting/one-page.md with 1-paragraph status, key metrics/example outputs (embed test output snippets), list of files changed (from final_patch and annotation.json), outstanding blockers, and 3 clear next actions with suggested owners/deadlines."
Cotomata,"Produce and deliver meeting-ready artifacts: a one-page summary, a short slide deck (1–6 slides) with speaker notes, and a Slack-ready summary that include final_patch diffs, test outputs, screenshots, blockers, and 3 clear next actions","Assemble slide deck and speaker notes: create docs/meeting/slides.md (1–6 slides) including title, problem, final_patch highlights, 2–3 screenshots, blockers, and speaker notes for each slide."
Cotomata,"Produce and deliver meeting-ready artifacts: a one-page summary, a short slide deck (1–6 slides) with speaker notes, and a Slack-ready summary that include final_patch diffs, test outputs, screenshots, blockers, and 3 clear next actions","Export artifacts to PDF and verify: run docs/meeting/assemble.sh (or fallback reveal-md/pandoc) to produce docs/meeting/one-page.pdf and docs/meeting/slides.pdf; open and QA both PDFs (check diffs, screenshots, and speaker notes present)."
Cotomata,"Produce and deliver meeting-ready artifacts: a one-page summary, a short slide deck (1–6 slides) with speaker notes, and a Slack-ready summary that include final_patch diffs, test outputs, screenshots, blockers, and 3 clear next actions","Prepare Slack-ready message: write docs/meeting/slack_msg.txt with a one-line decision/ask, three prioritized action items (owner + due date), and links/paths to one-page.pdf, slides.pdf, final_patch diff, and test logs; make it copy‑paste ready."
Cotomata,"Produce and deliver meeting-ready artifacts: a one-page summary, a short slide deck (1–6 slides) with speaker notes, and a Slack-ready summary that include final_patch diffs, test outputs, screenshots, blockers, and 3 clear next actions","Commit and publish artifacts: create branch meeting_artifacts/<timestamp>, commit docs/meeting/* and screenshots, push branch to origin, and produce a short verification checklist (files reachable, PDFs open) so the meeting lead can share or post the Slack message."
Cotomata,"Make the repository and test harness reproducible: provide a one‑line reproducible setup + run script (venv creation, dependencies, env vars), verify run_tests.sh behavior across Python 3.10+ binaries, and publish verification logs for teammates",
Cotomata,"Make the repository and test harness reproducible: provide a one‑line reproducible setup + run script (venv creation, dependencies, env vars), verify run_tests.sh behavior across Python 3.10+ binaries, and publish verification logs for teammates","Commit or apply the saved run_tests_fix.diff into a safe working branch (repro/fix/run_tests); verify run_tests.sh now: selects Python 3.12→3.11→3.10, creates/activates .venv with the chosen PYTHON_CMD, and fails with clear messages on FEATURE_PATCH missing or git apply failure."
Cotomata,"Make the repository and test harness reproducible: provide a one‑line reproducible setup + run script (venv creation, dependencies, env vars), verify run_tests.sh behavior across Python 3.10+ binaries, and publish verification logs for teammates","Create a one-line reproducible script docs/scripts/setup_and_run.sh (and executable wrapper ./repro.sh) that: clones the repo (or runs in-place), detects canonical dataset path (dspy vs dsyp), creates .venv with the selected PYTHON_CMD, installs dependencies from pyproject.toml, sources .env.example into env vars, and runs dataset/dspy_task/task8394/run_tests.sh; include usage, exit codes, and --dry-run mode."
Cotomata,"Make the repository and test harness reproducible: provide a one‑line reproducible setup + run script (venv creation, dependencies, env vars), verify run_tests.sh behavior across Python 3.10+ binaries, and publish verification logs for teammates","Verify Python detection across available interpreters: run the reproducible script with each candidate (python3.12, python3.11, python3.10, system python) on the test machine; capture and save logs that show the chosen PYTHON_CMD, `PYTHON_CMD --version`, and the runtime sys.version_info assertion; save outputs to docs/repro/logs/<timestamp>/interp-<version>.log."
Cotomata,"Make the repository and test harness reproducible: provide a one‑line reproducible setup + run script (venv creation, dependencies, env vars), verify run_tests.sh behavior across Python 3.10+ binaries, and publish verification logs for teammates","Execute the full test harness via the one-line script and capture complete test outputs (stdout/stderr), exit code, and any generated artifacts; store these under docs/repro/logs/<timestamp>/full-run.log and docs/repro/artifacts/; include the exact git commit hash and environment metadata (OS, pip list, pyproject.toml hash)."
Cotomata,"Make the repository and test harness reproducible: provide a one‑line reproducible setup + run script (venv creation, dependencies, env vars), verify run_tests.sh behavior across Python 3.10+ binaries, and publish verification logs for teammates","Publish reproducibility artifacts: add docs/repro/README.md that contains (a) the one-line command, (b) instructions to run per-interpreter verification, (c) links to saved logs and the run_tests_fix.diff, and (d) a short troubleshooting checklist for common failures (git ref sync, path name typos, FEATURE_PATCH apply failures, uncommitted local changes)."
Cotomata,"Make the repository and test harness reproducible: provide a one‑line reproducible setup + run script (venv creation, dependencies, env vars), verify run_tests.sh behavior across Python 3.10+ binaries, and publish verification logs for teammates",Add a lightweight CI/regression job (GitHub Actions or a simple script) that runs the one-line reproducible command on push to the repro/fix branch (or on a schedule); ensure it fails loudly and uploads logs/artifacts so the team is alerted if the test harness becomes non-reproducible.
Cotomata,"Complete and save Agent A/B evaluations in the Trajectory Comparison UI with concise failure analyses and linked evidence (final_patch diff, execution traces, profiler outputs) so they can be discussed and archived",
Cotomata,"Complete and save Agent A/B evaluations in the Trajectory Comparison UI with concise failure analyses and linked evidence (final_patch diff, execution traces, profiler outputs) so they can be discussed and archived","Collect and centralize evidence for Agent A (feature1) and Agent B (feature2): gather final_patch diffs, execution/test logs, profiler outputs (performance_profile.html), and relevant screenshots into docs/meeting/evidence/ (create folder if missing) and verify each file opens locally."
Cotomata,"Complete and save Agent A/B evaluations in the Trajectory Comparison UI with concise failure analyses and linked evidence (final_patch diff, execution traces, profiler outputs) so they can be discussed and archived","Open the Trajectory Comparison UI (http://localhost) for feature1 vs feature2, navigate to Final Patch / Test Output / Execution Trajectory pages, and capture 3 screenshots (Final Patch, Test Output, Merge Diff). Save them to docs/meeting/screenshots/ and note their file paths for linking."
Cotomata,"Complete and save Agent A/B evaluations in the Trajectory Comparison UI with concise failure analyses and linked evidence (final_patch diff, execution traces, profiler outputs) so they can be discussed and archived","Draft ratings and concise failure analyses for Agent A and Agent B: for each agent, choose Plan Quality / Execution Quality / Plan-Execution Match scores and write a 3–5 sentence failure analysis that cites specific evidence files (e.g., dataset/dspy_task/.../feature.patch, docs/meeting/evidence/run_tests_fix.diff, performance_profile.html, test logs). Save drafts to docs/meeting/agent_evaluations.json and docs/meeting/one-page.md."
Cotomata,"Complete and save Agent A/B evaluations in the Trajectory Comparison UI with concise failure analyses and linked evidence (final_patch diff, execution traces, profiler outputs) so they can be discussed and archived","Attach or link evidence in the Trajectory Comparison UI evaluation forms: populate the Agent A/B evidence fields with the local file paths or URLs (docs/meeting/evidence/*, docs/meeting/screenshots/*), paste the drafted failure_analysis text into the UI, and save the forms. Verify by reloading the evaluation page and confirming the fields persist."
Cotomata,"Complete and save Agent A/B evaluations in the Trajectory Comparison UI with concise failure analyses and linked evidence (final_patch diff, execution traces, profiler outputs) so they can be discussed and archived","Export and archive the saved evaluations: copy the saved evaluation JSON (or screenshot of the saved UI) to docs/meeting/agent_evaluations_saved.json, include the three screenshots and a brief slack_msg.txt summarizing the decision + links to artifacts, and confirm all files are committed or staged for the meeting."
Cotomata,"Complete and save Agent A/B evaluations in the Trajectory Comparison UI with concise failure analyses and linked evidence (final_patch diff, execution traces, profiler outputs) so they can be discussed and archived","Run a quick QA: open each linked artifact from the archived JSON (open diffs, test logs, and performance_profile.html) to ensure accessibility; take a final confirmation screenshot of the saved evaluation entries in the UI and place it in docs/meeting/screenshots/confirm_saved.png."
Cotomata,"Complete and save Agent A/B evaluations in the Trajectory Comparison UI with concise failure analyses and linked evidence (final_patch diff, execution traces, profiler outputs) so they can be discussed and archived",Notify meeting participants / prepare meeting handoff: produce a Slack-ready one-line summary + 3 action items in docs/meeting/slack_msg.txt (include links to docs/meeting/agent_evaluations_saved.json and screenshots) and post or be ready to paste it into the proj-cotomata-bench Slack channel before the discussion.
Cotomata,"Triage and produce concrete fixes or PR-ready patches for high-impact bugs: finalize run_tests.sh patch and branch/remote sync resolution, reproduce and profile the DSPy cache memory bug and recommend code fixes, and implement guardrails/regression tests for the Google Drive query loop",
Cotomata,"Triage and produce concrete fixes or PR-ready patches for high-impact bugs: finalize run_tests.sh patch and branch/remote sync resolution, reproduce and profile the DSPy cache memory bug and recommend code fixes, and implement guardrails/regression tests for the Google Drive query loop","Resolve git branch/remote sync error and document exact commands: fetch all refs, identify origin/<branch>, create or set upstream (e.g., git fetch --all; git branch -r; git checkout -b michael-dspy origin/michael-dspy or git branch --set-upstream-to=origin/<branch>), verify git pull/push succeed, and add a short runbook file docs/git_remote_fix.md with commands and verification steps."
Cotomata,"Triage and produce concrete fixes or PR-ready patches for high-impact bugs: finalize run_tests.sh patch and branch/remote sync resolution, reproduce and profile the DSPy cache memory bug and recommend code fixes, and implement guardrails/regression tests for the Google Drive query loop","Finalize and validate run_tests.sh patch on a safe branch: create branch (fix/run_tests-python-detection), apply run_tests_fix.diff, run the updated run_tests.sh end-to-end (create venv, verify PYTHON_CMD selection, test FEATURE_PATCH apply failure behavior), capture stdout/stderr logs and the successful --version / sys.version_info checks, commit changes, and produce a unified diff for review."
Cotomata,"Triage and produce concrete fixes or PR-ready patches for high-impact bugs: finalize run_tests.sh patch and branch/remote sync resolution, reproduce and profile the DSPy cache memory bug and recommend code fixes, and implement guardrails/regression tests for the Google Drive query loop","Open PR for run_tests.sh with verification checklist: push the branch, create a PR that includes the patch diff, the local test logs, an exact checklist of commands to reproduce the validation steps (venv creation, python --version, git apply failure case), and request reviewers."
Cotomata,"Triage and produce concrete fixes or PR-ready patches for high-impact bugs: finalize run_tests.sh patch and branch/remote sync resolution, reproduce and profile the DSPy cache memory bug and recommend code fixes, and implement guardrails/regression tests for the Google Drive query loop","Reproduce and profile the DSPy cache-memory bug: write a minimal reproducible script / unit test that triggers 'disabled cache still uses RAM', run scalene and tracemalloc to collect memory traces and performance_profile.html, record environment details (dspy commit/version, Python version, OS, env vars), and save artifacts under docs/diagnostics/dspy_cache_repro/."
Cotomata,"Triage and produce concrete fixes or PR-ready patches for high-impact bugs: finalize run_tests.sh patch and branch/remote sync resolution, reproduce and profile the DSPy cache memory bug and recommend code fixes, and implement guardrails/regression tests for the Google Drive query loop","Analyze profiler outputs and produce a concrete remediation (patch or PR-ready diff): produce a short diagnosis with root cause(s) from the traces, implement a minimal code change or a clear code-level recommendation (e.g., bypass cache key computation when cache disabled, avoid building large in-memory structures, short-circuit cache code paths), attach profiler artifacts, and open a draft PR or a detailed issue comment with the patch and test evidence."
Cotomata,"Triage and produce concrete fixes or PR-ready patches for high-impact bugs: finalize run_tests.sh patch and branch/remote sync resolution, reproduce and profile the DSPy cache memory bug and recommend code fixes, and implement guardrails/regression tests for the Google Drive query loop","Implement Drive-query guardrails and a regression test: modify src/precursor/main.py (or agent manager) to add max_query_count, exponential backoff, and a clear warning/exit when limits reached; add a unit/integration test in src/precursor/test_agent_manager.py that reproduces the loop and asserts the guardrail stops repeated Drive queries; run tests, capture logs, commit changes, and open a PR with the test and README notes."
Cotomata,Resolve coordination/merge issues around streaming semantics (StreamResponse/StreamListener is_last_chunk behavior) and merge feature branch diffs so agent-produced code aligns on interface contracts,
Cotomata,Resolve coordination/merge issues around streaming semantics (StreamResponse/StreamListener is_last_chunk behavior) and merge feature branch diffs so agent-produced code aligns on interface contracts,"Publish a short streaming interface spec (docs/streaming_contract.md) that defines StreamResponse fields (is_last_chunk boolean semantics, defaults, and caller obligations) and obtain sign-off from core collaborators"
Cotomata,Resolve coordination/merge issues around streaming semantics (StreamResponse/StreamListener is_last_chunk behavior) and merge feature branch diffs so agent-produced code aligns on interface contracts,"Implement the interface: update dspy/streaming/messages.py to include is_last_chunk (with type annotations/docstring), modify StreamResponse constructor, and update StreamListener.receive() to return/pass is_last_chunk; commit changes on a working branch"
Cotomata,Resolve coordination/merge issues around streaming semantics (StreamResponse/StreamListener is_last_chunk behavior) and merge feature branch diffs so agent-produced code aligns on interface contracts,"Add automated tests: unit tests for messages.py, a unit/integration test that verifies StreamListener end-of-stream behavior when is_last_chunk=True, and a regression test that fails on the old behavior"
Cotomata,Resolve coordination/merge issues around streaming semantics (StreamResponse/StreamListener is_last_chunk behavior) and merge feature branch diffs so agent-produced code aligns on interface contracts,"Resolve git conflicts and merge feature diffs on branch feature1_feature2_k1: fetch remote refs, create/switch local branch, apply/rebase feature patches, resolve conflicts guided by the spec and tests, and commit a clean merged branch (include exact git commands in the merge commit message)"
Cotomata,Resolve coordination/merge issues around streaming semantics (StreamResponse/StreamListener is_last_chunk behavior) and merge feature branch diffs so agent-produced code aligns on interface contracts,"Run full local verification: execute run_tests.sh (or tools/evaluate_parallel.sh) and the new streaming tests, capture logs/perf output, iterate on fixes until tests pass, and store logs/docs in docs/meeting/test_logs/"
Cotomata,Resolve coordination/merge issues around streaming semantics (StreamResponse/StreamListener is_last_chunk behavior) and merge feature branch diffs so agent-produced code aligns on interface contracts,"Open a PR with the spec, code changes, tests, and verification logs; update Trajectory Comparison/annotation.json and send a Slack summary with the change, test results, and next steps for roll-out"
Cotomata,"Consolidate meeting automation and repository hygiene: finalize docs/meeting templates and assemble.sh, standardize canonical paths (dspy vs dsyp), save artifacts under docs/meeting/, and create onboarding notes for running the Trajectory Comparison UI",
Cotomata,"Consolidate meeting automation and repository hygiene: finalize docs/meeting templates and assemble.sh, standardize canonical paths (dspy vs dsyp), save artifacts under docs/meeting/, and create onboarding notes for running the Trajectory Comparison UI","Confirm and standardize canonical dataset path (dspy) across the repo and update scripts/docs: detect all 'dspy'/'dsyp' instances, choose canonical name, commit a non-breaking rename or add a small wrapper mapping + update run_tests.sh and docs. Deliverable: commit/PR and a short changelog entry."
Cotomata,"Consolidate meeting automation and repository hygiene: finalize docs/meeting templates and assemble.sh, standardize canonical paths (dspy vs dsyp), save artifacts under docs/meeting/, and create onboarding notes for running the Trajectory Comparison UI","Finalize docs/meeting templates (slides.md, one-page.md, slack_msg.txt, agent_evaluations.json) with placeholders and example content: ensure speaker notes, screenshots placeholders, files-changed list, blockers, and 3 action items are populated. Deliverable: finalized template files in docs/meeting/."
Cotomata,"Consolidate meeting automation and repository hygiene: finalize docs/meeting templates and assemble.sh, standardize canonical paths (dspy vs dsyp), save artifacts under docs/meeting/, and create onboarding notes for running the Trajectory Comparison UI","Implement and harden docs/meeting/assemble.sh: add dependency checks (reveal-md/pandoc/puppeteer/node), capture specified UI pages (Final Patch, Merge Diff, Test Output, Agent Evaluation), export one-page.pdf and slides.pdf, create slack_msg.txt and agent_evaluations.json, and include usage/help text. Deliverable: executable assemble.sh with inline usage and a smoke-test script."
Cotomata,"Consolidate meeting automation and repository hygiene: finalize docs/meeting templates and assemble.sh, standardize canonical paths (dspy vs dsyp), save artifacts under docs/meeting/, and create onboarding notes for running the Trajectory Comparison UI","Create reproducible artifact run demonstrating assemble.sh (capture + export): run assemble.sh on the local Trajectory Comparison UI, collect screenshots and generated PDFs under docs/meeting/screenshots and docs/meeting/outputs, and commit the example artifacts. Deliverable: docs/meeting/one-page.pdf, slides.pdf, screenshots and a commit with logs showing success."
Cotomata,"Consolidate meeting automation and repository hygiene: finalize docs/meeting templates and assemble.sh, standardize canonical paths (dspy vs dsyp), save artifacts under docs/meeting/, and create onboarding notes for running the Trajectory Comparison UI","Write an onboarding runbook for the Trajectory Comparison UI and automation (docs/meeting/onboarding.md): exact clone + setup commands (git clone experiments_logs, cd annotation, npm install, npm run dev), environment/credentials placement (credentials.json, .env.example), how to run assemble.sh, expected outputs, and quick troubleshooting steps. Deliverable: onboarding.md added to docs/meeting/."
Cotomata,"Consolidate meeting automation and repository hygiene: finalize docs/meeting templates and assemble.sh, standardize canonical paths (dspy vs dsyp), save artifacts under docs/meeting/, and create onboarding notes for running the Trajectory Comparison UI","Add a small verification checklist / CI-friendly sanity check script: include a script (docs/meeting/check_repo_paths.sh) that verifies canonical paths exist, assemble.sh dependencies are installed, and the annotation UI is reachable at http://localhost; add instructions to run these checks before meetings. Deliverable: check script and brief note in onboarding.md."
Background Agents (Precursor),"Stabilize and harden the background-agent runtime (notification/queue handling, retry/pending-task tracking) with deterministic integration tests and CI so the pipeline is reliable and observable for demos and evaluation.",
Background Agents (Precursor),"Stabilize and harden the background-agent runtime (notification/queue handling, retry/pending-task tracking) with deterministic integration tests and CI so the pipeline is reliable and observable for demos and evaluation.",Create a deterministic reproduction for the 'skipping notification' case: add a small tmp_path CSV fixture and a csv_simulator run_once/step invocation (or test harness) that reproducibly emits the sequence triggering the skipped-notification log and save the captured trace (dev/survey/notification_repro.log).
Background Agents (Precursor),"Stabilize and harden the background-agent runtime (notification/queue handling, retry/pending-task tracking) with deterministic integration tests and CI so the pipeline is reliable and observable for demos and evaluation.","Add injectable MockTelemetrySink and MockNotificationSink and emit structured telemetry events from ui_manager and agent_manager (observation_queued, batch_processed, project_transition_detected, notification_sent, notification_skipped). Provide default backwards-compatible sinks and unit tests that assert emitted payloads instead of log-string matching."
Background Agents (Precursor),"Stabilize and harden the background-agent runtime (notification/queue handling, retry/pending-task tracking) with deterministic integration tests and CI so the pipeline is reliable and observable for demos and evaluation.","Implement pending-agent-completed-task tracking and retry/replay logic in agent_manager/ui_manager: reliably record completed tasks, surface pending counts to the notification decision, implement a small retry/replay policy (per-task max_retries + exponential/backoff bounds), and add metrics/log lines for queue size and retry events."
Background Agents (Precursor),"Stabilize and harden the background-agent runtime (notification/queue handling, retry/pending-task tracking) with deterministic integration tests and CI so the pipeline is reliable and observable for demos and evaluation.","Fix queue/coalescing and notification decision logic: make batching deterministic (latest-wins behavior explicit), add loop-guards for repeated identical tool calls, normalize input validation paths that cause fallback loops (e.g., websearch arg mapping), and add debug-level logs when items are dropped or malformed."
Background Agents (Precursor),"Stabilize and harden the background-agent runtime (notification/queue handling, retry/pending-task tracking) with deterministic integration tests and CI so the pipeline is reliable and observable for demos and evaluation.","Extend csv_simulator with a deterministic mode (injectable clock / step/run_once) if needed, then write deterministic integration tests (tests/test_project_transition_observer.py) that cover: project transition detection, batch processing/coalescing, notification_skipped, and notification_sent using the MockTelemetry/Notification sinks."
Background Agents (Precursor),"Stabilize and harden the background-agent runtime (notification/queue handling, retry/pending-task tracking) with deterministic integration tests and CI so the pipeline is reliable and observable for demos and evaluation.","Open a reviewer-friendly PR that includes: code changes, new tests, how-to-run instructions (pytest -k project_transition), a short checklist, CI job enabling the new tests, and verification notes (including repro log paths). Address review comments and merge once CI is green."
Background Agents (Precursor),"Produce meeting-ready materials and handoff assets (exported Keynote/PDF with speaker notes, 1‑page brief, 2–3 slide quick deck, demo screenshots) and synthesize immediate feedback into prioritized action items.",
Background Agents (Precursor),"Produce meeting-ready materials and handoff assets (exported Keynote/PDF with speaker notes, 1‑page brief, 2–3 slide quick deck, demo screenshots) and synthesize immediate feedback into prioritized action items.",Export current Keynote as a PDF with speaker notes and save a .key backup: presentations/Precursor_MEETING.pdf and presentations/Precursor_MEETING.key (confirm files open correctly in Preview/Keynote).
Background Agents (Precursor),"Produce meeting-ready materials and handoff assets (exported Keynote/PDF with speaker notes, 1‑page brief, 2–3 slide quick deck, demo screenshots) and synthesize immediate feedback into prioritized action items.",Finalize 30–60s speaker notes for all slides and produce a one-slide executive summary; embed speaker notes into the exported PDF and save the executive summary as presentations/executive_summary_Precursor.pdf and dev/presentations/executive_summary_Precursor.md.
Background Agents (Precursor),"Produce meeting-ready materials and handoff assets (exported Keynote/PDF with speaker notes, 1‑page brief, 2–3 slide quick deck, demo screenshots) and synthesize immediate feedback into prioritized action items.","Crop 1–2 demo screenshots from dev/survey/screenshots, save them as dev/survey/screenshots/cropped_demo_1.png and cropped_demo_2.png, and embed them into the PDF and backup .key."
Background Agents (Precursor),"Produce meeting-ready materials and handoff assets (exported Keynote/PDF with speaker notes, 1‑page brief, 2–3 slide quick deck, demo screenshots) and synthesize immediate feedback into prioritized action items.","Produce a one‑page meeting brief (<=300 words) containing current status, a CSV snippet from dev/survey/pipeline_run.csv, top 3 accomplishments, top 3 blockers/questions, and 3 next actions; save to dev/presentations/one_pager_Precursor_MEETING.md."
Background Agents (Precursor),"Produce meeting-ready materials and handoff assets (exported Keynote/PDF with speaker notes, 1‑page brief, 2–3 slide quick deck, demo screenshots) and synthesize immediate feedback into prioritized action items.","Create a 2–3 slide quick deck (Title; Status + metrics; Blockers + asks) with 30–60s speaker notes per slide, export to presentations/Precursor_QUICK_DECK.pdf, and include the cropped demo screenshot(s)."
Background Agents (Precursor),"Produce meeting-ready materials and handoff assets (exported Keynote/PDF with speaker notes, 1‑page brief, 2–3 slide quick deck, demo screenshots) and synthesize immediate feedback into prioritized action items.","Synthesize meeting feedback into prioritized action items grouped by Immediate (today/this week), Near-term (2–4 weeks), and Longer-term; for each item include a short description, rationale, estimated effort (quick/medium/large), suggested owner(s), and a recommended deadline. Save to dev/presentations/meeting_action_items_Precursor.md and add a short summary slide to the quick deck."
Background Agents (Precursor),"Produce meeting-ready materials and handoff assets (exported Keynote/PDF with speaker notes, 1‑page brief, 2–3 slide quick deck, demo screenshots) and synthesize immediate feedback into prioritized action items.","Run a final verification & handoff checklist: confirm all files exist at the saved paths, open each exported PDF to verify speaker notes and embedded images, commit or copy artifacts to the repo/presentations folder (or upload to the agreed share), and send a paste‑ready handoff message to Michael and Michelle listing file paths, one‑line status, and 1–2 asks."
Background Agents (Precursor),"Finalize the user-study protocol and run an N=10 pilot (privacy/LLM-logging plan, pre/post surveys, interview prompts), collect pilot data, and produce an initial analysis report suitable for meeting discussion.",
Background Agents (Precursor),"Finalize the user-study protocol and run an N=10 pilot (privacy/LLM-logging plan, pre/post surveys, interview prompts), collect pilot data, and produce an initial analysis report suitable for meeting discussion.","Finalize and freeze the user‑study protocol: update Google Doc ‘User Study Design’ to include conditions, N=10 rationale, exact task scripts, pre/post survey questions, interview prompts, session timing, and a one‑page study summary + 3‑slide brief saved to dev/presentations/ (deliverable: User_Study_Protocol_FINAL.docx or Google Doc link)."
Background Agents (Precursor),"Finalize the user-study protocol and run an N=10 pilot (privacy/LLM-logging plan, pre/post surveys, interview prompts), collect pilot data, and produce an initial analysis report suitable for meeting discussion.","Define and document the privacy & LLM‑logging plan: produce a short privacy appendix with consent language, what LLM inputs/outputs are logged, hashing/anonymization scheme, retention policy, access controls, and a sample logged record schema; save as docs/USER_STUDY_PRIVACY.md and add test logging scripts/fixtures in dev/survey/logging_fixtures/."
Background Agents (Precursor),"Finalize the user-study protocol and run an N=10 pilot (privacy/LLM-logging plan, pre/post surveys, interview prompts), collect pilot data, and produce an initial analysis report suitable for meeting discussion.","Prepare all study materials and runbook: produce participant-facing materials (consent form, recruitment screener, onboarding instructions, task prompts), moderator script, survey forms (Google Forms/CSV), and a one‑page runbook with step-by-step session flow; save artifacts to dev/presentations/ and dev/study_materials/."
Background Agents (Precursor),"Finalize the user-study protocol and run an N=10 pilot (privacy/LLM-logging plan, pre/post surveys, interview prompts), collect pilot data, and produce an initial analysis report suitable for meeting discussion.","Recruit and schedule N=10 pilot participants: send recruitment messages/screener, confirm consent, and schedule 10 sessions (or recruit a convenience sample), logging participant IDs and assigned condition; deliverable: confirmed schedule and participant roster in dev/study_materials/participant_roster.csv."
Background Agents (Precursor),"Finalize the user-study protocol and run an N=10 pilot (privacy/LLM-logging plan, pre/post surveys, interview prompts), collect pilot data, and produce an initial analysis report suitable for meeting discussion.","Run the N=10 pilot sessions and collect data: conduct all sessions per the runbook, capture LLM logs and UI events per the logging schema, collect pre/post surveys and interview recordings/notes, and back up raw data to a secure, access‑controlled folder (dev/survey/raw_pilot_data/)."
Background Agents (Precursor),"Finalize the user-study protocol and run an N=10 pilot (privacy/LLM-logging plan, pre/post surveys, interview prompts), collect pilot data, and produce an initial analysis report suitable for meeting discussion.","Process, anonymize, and QC the pilot data: run preprocessing scripts to remove PII/anonymize identifiers, validate completeness (surveys + logs + recordings), produce cleaned datasets and a short QC report (dev/survey/cleaned_pilot_data/ + dev/survey/pilot_qc_report.md)."
Background Agents (Precursor),"Finalize the user-study protocol and run an N=10 pilot (privacy/LLM-logging plan, pre/post surveys, interview prompts), collect pilot data, and produce an initial analysis report suitable for meeting discussion.","Produce initial analysis and meeting deliverables: create a concise initial analysis report (quantitative summaries, key qualitative quotes, observed issues), a one‑page executive summary, and a 2–3 slide meeting brief with 30–60s speaker notes; save to dev/presentations/Precursor_Pilot_Report.pdf and prepare a short list of recommended next actions for discussion."
Background Agents (Precursor),"Harden agent I/O and task metadata: enrich agent-candidate rows with explicit deliverable metadata and acceptance criteria, fix serializers (e.g., gum_source _serialize_recent_propositions) to produce deterministic, LLM-ready inputs, and add fixtures for dry-runs.",
Background Agents (Precursor),"Harden agent I/O and task metadata: enrich agent-candidate rows with explicit deliverable metadata and acceptance criteria, fix serializers (e.g., gum_source _serialize_recent_propositions) to produce deterministic, LLM-ready inputs, and add fixtures for dry-runs.","Define and commit an enriched agent-candidate schema and mapping: add a documented CSV schema (deliverable_type, output_filename/output_path, template_reference, example_inputs, one-line acceptance_criteria, normalized task_description, standardized project_tags) and a small mapping spec (YAML/README) describing defaults and allowed values."
Background Agents (Precursor),"Harden agent I/O and task metadata: enrich agent-candidate rows with explicit deliverable metadata and acceptance criteria, fix serializers (e.g., gum_source _serialize_recent_propositions) to produce deterministic, LLM-ready inputs, and add fixtures for dry-runs.","Implement an auto-fill & validation script to enrich existing CSV rows: create dev/survey/enrich_agent_candidates.py that reads pipeline_run.agent_candidates.csv, fills defaults for common deliverable_types, normalizes task_description to an imperative sentence, validates fields, and writes a canonical enriched CSV (dev/survey/pipeline_run.agent_candidates.enriched.csv); include unit tests for validation rules."
Background Agents (Precursor),"Harden agent I/O and task metadata: enrich agent-candidate rows with explicit deliverable metadata and acceptance criteria, fix serializers (e.g., gum_source _serialize_recent_propositions) to produce deterministic, LLM-ready inputs, and add fixtures for dry-runs.","Harden gum_source._serialize_recent_propositions: fix function to defensively handle str/None/malformed items, build deterministic newline-delimited lines, escape internal newlines, add debug logging for malformed items, and add unit tests tests/test_gum_serializer.py covering string input, list-of-objects, empty list, and malformed items."
Background Agents (Precursor),"Harden agent I/O and task metadata: enrich agent-candidate rows with explicit deliverable metadata and acceptance criteria, fix serializers (e.g., gum_source _serialize_recent_propositions) to produce deterministic, LLM-ready inputs, and add fixtures for dry-runs.","Expose and consume enriched metadata in the agent pipeline: update agent task-creation code (src/precursor/managers/agent_manager.py and src/precursor/agents/mcp_agent.py) so deliverable_type, output_path/template_reference, example_inputs, and acceptance_criteria are passed into task prompts/tooling; add tests/mocks asserting the agent receives and uses those fields."
Background Agents (Precursor),"Harden agent I/O and task metadata: enrich agent-candidate rows with explicit deliverable metadata and acceptance criteria, fix serializers (e.g., gum_source _serialize_recent_propositions) to produce deterministic, LLM-ready inputs, and add fixtures for dry-runs.","Add fixtures and deterministic dry-run integration tests: create small tmp_path CSV fixtures and a dry-run command (e.g., scripts/dry_run_agent_pipeline.py or pytest integration) using src/precursor/observers/csv_simulator.py deterministic mode to run the pipeline end-to-end; assert generated task payloads, serializer outputs, and example produced artifacts (e.g., placeholder slide file or one-pager draft) are present."
Background Agents (Precursor),"Harden agent I/O and task metadata: enrich agent-candidate rows with explicit deliverable metadata and acceptance criteria, fix serializers (e.g., gum_source _serialize_recent_propositions) to produce deterministic, LLM-ready inputs, and add fixtures for dry-runs.","Publish tests/docs and CI notes: add test instructions (pytest -k agent_metadata OR how to run dry-run), update README/dev notes about the enriched CSV schema and PRECURSOR_DISABLE_CALENDAR for hermetic runs, and ensure new tests are green in CI (or add a short CI job to run the dry-run smoke-test)."
Background Agents (Precursor),"Complete context_agent ↔ mcp_agent integration and tool-selection logic (input validation, loop-guards, preference rules) to enable reproducible end-to-end local runs and reliable tool routing for internet vs. Drive queries.",
Background Agents (Precursor),"Complete context_agent ↔ mcp_agent integration and tool-selection logic (input validation, loop-guards, preference rules) to enable reproducible end-to-end local runs and reliable tool routing for internet vs. Drive queries.","Create a minimal, reproducible end-to-end trace and test fixture that reproduces the repeated-drive tool-selection loop and ContextBuilderAgent parsing failure (save as dev/survey/tool_selection_repro.log and tests/fixtures/tool_selection_repro.jsonl)."
Background Agents (Precursor),"Complete context_agent ↔ mcp_agent integration and tool-selection logic (input validation, loop-guards, preference rules) to enable reproducible end-to-end local runs and reliable tool routing for internet vs. Drive queries.","Add defensive input validation and normalization for websearch arguments (map/normalize invalid enum values, reject/convert short-codes like 'pd') and add unit tests that assert invalid inputs no longer produce invalid websearch calls."
Background Agents (Precursor),"Complete context_agent ↔ mcp_agent integration and tool-selection logic (input validation, loop-guards, preference rules) to enable reproducible end-to-end local runs and reliable tool routing for internet vs. Drive queries.","Implement loop-guards and retry policies in the tool-dispatch layer: per-task max_retries, per-call timeout, and loop-detection (if same tool+args invoked > N times within T seconds) with deterministic fallback behavior; include unit tests that mock repeated tool failures and assert correct fallback or abort."
Background Agents (Precursor),"Complete context_agent ↔ mcp_agent integration and tool-selection logic (input validation, loop-guards, preference rules) to enable reproducible end-to-end local runs and reliable tool routing for internet vs. Drive queries.","Add an explicit tool-preference rule and decision-level diagnostic logging: prefer websearch for internet-facing queries unless Drive is explicitly required; log chosen tool, input args, and the heuristic/rationale for selection. Add tests asserting preference behavior."
Background Agents (Precursor),"Complete context_agent ↔ mcp_agent integration and tool-selection logic (input validation, loop-guards, preference rules) to enable reproducible end-to-end local runs and reliable tool routing for internet vs. Drive queries.","Harden ContextBuilderAgent parsing and Zod handling: sanitize LM/webscrape outputs (strip/normalize empty strings), provide safe parsing/fallback defaults for missing fields, and add unit/integration tests using malformed fixtures to assert no InvalidLiteralError is raised and that helpful diagnostics are logged."
Background Agents (Precursor),"Complete context_agent ↔ mcp_agent integration and tool-selection logic (input validation, loop-guards, preference rules) to enable reproducible end-to-end local runs and reliable tool routing for internet vs. Drive queries.","Complete the context_agent ↔ mcp_agent integration: fix function signatures and imports, ensure build_toolset is called correctly, and make d_selected_mcp_servers drive/websearch selection effective; provide a one-command local smoke-test (example: PRECURSOR_DISABLE_CALENDAR=1 python -m precursor.tools.gather_project_context --task '...') that produces a captured tool_call trace showing correct routing."
Background Agents (Precursor),"Complete context_agent ↔ mcp_agent integration and tool-selection logic (input validation, loop-guards, preference rules) to enable reproducible end-to-end local runs and reliable tool routing for internet vs. Drive queries.","Add deterministic integration tests asserting tool routing, loop-guard behavior, and graceful parsing; document how to run the repro and tests (README/dev note), and open a PR with a reviewer-friendly description, test run instructions, and the smoke-test command."
Background Agents (Precursor),"Draft and iterate a polished paper/manuscript draft (integrating prototype design, pilot results, evaluation plan, and related-work) ready for internal review and submission.",
Background Agents (Precursor),"Draft and iterate a polished paper/manuscript draft (integrating prototype design, pilot results, evaluation plan, and related-work) ready for internal review and submission.","Stabilize the prototype and experiment pipeline: fix critical bugs, ensure deterministic tests pass, and provide a one-command reproducible experiment script that generates raw outputs (logs/CSV) used by the paper"
Background Agents (Precursor),"Draft and iterate a polished paper/manuscript draft (integrating prototype design, pilot results, evaluation plan, and related-work) ready for internal review and submission.","Run and complete the N=10 pilot (per finalized protocol): collect raw logs, pre/post surveys, and interview notes; verify privacy/LLM-usage logging and save canonical raw data files for analysis"
Background Agents (Precursor),"Draft and iterate a polished paper/manuscript draft (integrating prototype design, pilot results, evaluation plan, and related-work) ready for internal review and submission.","Analyze pilot data and produce publication-ready figures/tables: compute primary metrics, run required statistical tests, create 3–6 figures (performance/behavior plots, example dialogues/traces, and a result table) with captions and source CSVs"
Background Agents (Precursor),"Draft and iterate a polished paper/manuscript draft (integrating prototype design, pilot results, evaluation plan, and related-work) ready for internal review and submission.","Draft core manuscript sections: write Methods (system & implementation), Experimental Protocol, Results (with figures/tables), and Discussion/Limitations; include clear one-paragraph TL;DR and contribution bullets"
Background Agents (Precursor),"Draft and iterate a polished paper/manuscript draft (integrating prototype design, pilot results, evaluation plan, and related-work) ready for internal review and submission.","Write and integrate Related Work & Positioning: incorporate key papers (including 'Task Completion Agents are Not Ideal Collaborators'), add explicit design implications for Precursor, and add 3–5 paste-ready quote snippets for slides/meeting docs"
Background Agents (Precursor),"Draft and iterate a polished paper/manuscript draft (integrating prototype design, pilot results, evaluation plan, and related-work) ready for internal review and submission.","Prepare reproducibility & supplementary materials: freeze a code snapshot, add experiment scripts/notebooks to a reproducibility folder, produce an appendix with task templates, parameter settings, and IRB/privacy notes, and create a README with a reproducible run and figure-generation steps"
Background Agents (Precursor),"Draft and iterate a polished paper/manuscript draft (integrating prototype design, pilot results, evaluation plan, and related-work) ready for internal review and submission.","Complete internal review and submission prep: circulate draft to coauthors with a review checklist, incorporate feedback, format to the target venue template, prepare cover letter/author metadata/ethics statement, and finalize the submission bundle"
